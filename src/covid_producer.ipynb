{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fff4df7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Faker\n",
      "  Downloading Faker-8.12.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /opt/conda/lib/python3.9/site-packages (from Faker) (2.8.2)\n",
      "Collecting text-unidecode==1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78 kB 8.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.4->Faker) (1.16.0)\n",
      "Installing collected packages: text-unidecode, Faker\n",
      "Successfully installed Faker-8.12.1 text-unidecode-1.3\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (1.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Collecting tweepy\n",
      "  Downloading tweepy-3.10.0-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.9/site-packages (from tweepy) (2.26.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.9/site-packages (from tweepy) (1.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy) (2.0.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n",
      "Installing collected packages: requests-oauthlib, tweepy\n",
      "Successfully installed requests-oauthlib-1.3.0 tweepy-3.10.0\n",
      "Collecting confluent_kafka\n",
      "  Downloading confluent_kafka-1.7.0-cp39-cp39-manylinux2010_x86_64.whl (2.7 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.7 MB 1.1 MB/s eta 0:00:01     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 2.0 MB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: confluent-kafka\n",
      "Successfully installed confluent-kafka-1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Faker\n",
    "!pip install pandas \n",
    "!pip install tweepy\n",
    "!pip install confluent_kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de5649ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from confluent_kafka import Producer\n",
    "import json\n",
    "import tweepy\n",
    "\n",
    "producer = Producer(**{\"bootstrap.servers\": \"kafka2:19092\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6632527",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"hK08N3zIwkJLrF6BVK52b3aS8\"\n",
    "consumer_secret = \"8M22ppkZzb3sC9u4acUZK5IBr9nsLSByctTOoUI3Y5THEMRk7s\"\n",
    "access_token = \"774855303321886720-JxdOM3ieqEVck6l0rYJmSIV3A412anW\"\n",
    "access_token_secret = \"AoJgcvbtWmikzHaoOwH2rURrzoRwbBGgoV4oEASumNMzF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16602009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words to track\n",
    "WORDS = ['#coronavirus', '#COVID-19', '#COVID19', '#COVID'] #, '#SocialDistancing', '#pandemic']\n",
    "raw_tweets_topic = \"1_RAW_tweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ee79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamListener(tweepy.StreamListener):\n",
    "    # This is a class provided by tweepy to access the Twitter Streaming API.\n",
    "\n",
    "    def on_connect(self):\n",
    "        # Called initially to connect to the Streaming API\n",
    "        print(\"You are now connected to the streaming API.\")\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        # On error - if an error occurs, display the error / status code\n",
    "        print(\"Error received in kafka producer \" + repr(status_code))\n",
    "        \n",
    "        return True \n",
    "    \n",
    "    def preprocess(self, tweetData):\n",
    "        userID = '-'\n",
    "        tweetText = '-'\n",
    "        hashTags = []\n",
    "        location_full_name = '-'\n",
    "        created_at = '-'\n",
    "        favoriteCount = 0\n",
    "        reTweetCount = 0\n",
    "        \n",
    "\n",
    "        try:\n",
    "            userID = tweetData[\"user\"][\"id\"]\n",
    "            \n",
    "            if tweetData[\"truncated\"] == True:\n",
    "                tweetText = tweetData[\"extended_tweet\"][\"full_text\"]\n",
    "                hashTags = [ hTag[\"text\"] for hTag in tweetData[\"extended_tweet\"][\"entities\"][\"hashtags\"] ]\n",
    "            else:\n",
    "                tweetText = tweetData[\"text\"]\n",
    "                hashTags = [ hTag[\"text\"] for hTag in tweetData[\"entities\"][\"hashtags\"] ]\n",
    "\n",
    "            if hashTags == []:\n",
    "                return {}\n",
    "\n",
    "            if \"user\" in tweetData and tweetData[\"user\"] != None:\n",
    "                location_full_name = tweetData[\"user\"][\"location\"]\n",
    "                \n",
    "            created_at = tweetData[\"created_at\"]\n",
    "            favoriteCount = tweetData[\"favorite_count\"]\n",
    "            reTweetCount = tweetData[\"retweet_count\"]\n",
    "            \n",
    "\n",
    "            rec = {'userID': userID, \n",
    "                   'tweetText': tweetText, \n",
    "                   'hashTags': hashTags, \n",
    "                   'location_full_name': location_full_name,\n",
    "                   'favoriteCount': favoriteCount,\n",
    "                   'reTweetCount': reTweetCount,\n",
    "                   'created_at': created_at}\n",
    "\n",
    "            return json.dumps(rec)\n",
    "\n",
    "        except Exception as ex:\n",
    "            print('Exception while parsing')\n",
    "            print(str(ex))\n",
    "\n",
    "    def on_data(self, data):\n",
    "        \"\"\" This method is called whenever new data arrives from live stream.\n",
    "        We asynchronously push this data to kafka queue\"\"\"\n",
    "        try:\n",
    "            parsed = json.loads(data)\n",
    "\n",
    "            \n",
    "            if \"user\" in parsed and \"location\" in parsed[\"user\"]:\n",
    "                if parsed[\"user\"][\"location\"] != None:\n",
    "\n",
    "                    processed = self.preprocess(parsed)\n",
    "\n",
    "                    if isinstance(processed, str):\n",
    "                        producer.produce(raw_tweets_topic, value=processed.encode('utf-8'))\n",
    "                        producer.flush()\n",
    "\n",
    "                        print(parsed[\"text\"])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"error! : \" + str(e))\n",
    "            return False #stop stream\n",
    "\n",
    "        return True\n",
    "\n",
    "    def on_timeout(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80622eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: ['#coronavirus', '#COVID-19', '#COVID19', '#COVID']\n",
      "You are now connected to the streaming API.\n",
      "RT @WIONews: Indian authorities are restricting religious festivals due to the threat of the outbreak of #COVID19's third wave. Several gov‚Ä¶\n",
      "Woot! Fully vaccinated and ready to kick #COVID19 in the ghoulies. https://t.co/ITPEofGP0D\n",
      "RT @carolJhedges: üò¨Is it just my deeply suspicious mind, or is this 'let's fund the #NHS &amp; #socialcare' actually a ruse to grab a refund fo‚Ä¶\n",
      "According to predictions made about two weeks ago by Hebrew University researchers, the #coronavirus infection rate‚Ä¶ https://t.co/SeUR1AZDhU\n",
      "RT @OrganicConsumer: Factory pig farms are spreading #COVID19: ‚û°Ô∏è  \"This has to do with two things: unhealthy human labor and poor conditio‚Ä¶\n",
      "RT @DrEricDing: Wow‚Äî‚ÄúEvery kindegarten teacher‚Äù at Kinder Ranch Elementary in @cisdnews tested positive for #COVID19. However, the school s‚Ä¶\n",
      "We've crossed the 14 million mark, #Mzansi. üëèüèæ If you can help someone get their jab, please do. Together, we can d‚Ä¶ https://t.co/oPq6iay0KX\n",
      "‚≠ïÔ∏è #Georgia reported 2,455 #coronavirus cases, 4,427 recoveries, and 58 deaths on September 9\n",
      "\n",
      "‚≠ïÔ∏è Read more üëâ‚Ä¶ https://t.co/n2CcoS5pe3\n",
      "https://t.co/wQoLZCLWTk avail for acquisition, lease &amp; joint #venture\n",
      "#vaccuate #vaccine #vaccinate¬† #vaccination‚Ä¶ https://t.co/VKl29evdsr\n",
      "RT @NewIndianXpress: A new sublineage AY.12, of the #DeltaVariant of #Coronavirus, that was recently classified in Israel is now being seen‚Ä¶\n",
      "We urge all #workers and their families to go for #vaccine jabs to curb the devastating effects of #Covid19 to huma‚Ä¶ https://t.co/eaFHH8gYn4\n",
      "Islamabad: Daily update on #coronavirus cases,  9th September, 2021.\n",
      "\n",
      "‚Ä¢  4,560 tests conducted in the last 24 hours‚Ä¶ https://t.co/a32iibcDos\n",
      "RT @CrabbBrendan: Brilliant piece. What an exciting prospect for #COVID19 and our health more generally. Featuring extensively Prof Lidia M‚Ä¶\n",
      "RT @MissStixy: #JaneneHoskovec is a vile, sick and cruel individual. She may also need psychiatric help. Now she has no job &amp; will live on‚Ä¶\n",
      "I‚Äôve reached that point where I‚Äôm now reluctant to buy any tickets for gigs, just incase they pull those ‚Äúpassports‚Ä¶ https://t.co/LbdMGjyGnU\n",
      "#Drug #traffickers have adapted the situation quicker than we thought. Despite of #COVID-19 and serious lock-down i‚Ä¶ https://t.co/TVLQHOo4fK\n",
      "#Coronavirus: #Thane district reports 243 new cases; four more die\n",
      "#Covid_19 \n",
      " https://t.co/anOSWsiAss\n",
      "*Singapore to end movement restrictions for migrant workers #covid\n",
      "#COVID19 #Vaccines by brand administered in #Thailand as of Sept 7, 2021 . #Expatvac. https://t.co/KIUxdsHzPk\n",
      "India Reports 43,263 New COVID-19 Cases in Past 24 Hours, Kerala Adds 30,196 Infections \n",
      "#COVID19 #Coronavirus‚Ä¶ https://t.co/c4qHXBAxZN\n",
      "Vaccine manufacturer Novavax has announced it is developing a joint #COVID19/flu shot that is currently in the tria‚Ä¶ https://t.co/lNEaHcHBdO\n",
      "How Valencia crushed Covid with Artificial Intelligence  https://t.co/vSC1KfsZXW  #ai #artificialintelligence‚Ä¶ https://t.co/Y29dbH2qg5\n",
      "via @RichardEudes - How Valencia crushed Covid with AI https://t.co/lMjT2iXblE #artificialintelligence, #bigdata,‚Ä¶ https://t.co/8bjDyTKafr\n",
      "RT @unityblue: 60% oil+gas &amp; 90% coal unextracted to stay within 1.5¬∞C carbon budget by 2050\n",
      "\n",
      "We've used ~1.2‚Äâ¬∞C‚û°Ô∏èrecordüåé:\n",
      "#floods &gt;100's‚ò†Ô∏è‚Ä¶\n",
      "The city ,where I am staying, treats 2 types of the vaccine.\n",
      "\n",
      " 1. Pfizer's\n",
      " 2. Takeda &amp; Moderna's\n",
      " \n",
      "1st was Since S‚Ä¶ https://t.co/aW59mH48vf\n",
      "RT @varnasuthan1104: SLMA moots Sinopharm for 18-60 group - The Morning - Sri Lanka News #lka #srilanka #COVID19LK #corona #covid19 https:/‚Ä¶\n",
      "Awful news from #Tetovo. #NorthMacedonia\n",
      "Now playing on African Affairs Radio: The Tide Is High by Johnny Clarke! Tune in now.\n",
      "Live (Nonstop African Music):‚Ä¶ https://t.co/sicwIPoEk7\n",
      "RT @DawsonEJ: Does. Not. Understand. His. Job. #auspol\n",
      "RT @DataScientistsF: via @RichardEudes - How Valencia crushed Covid with AI https://t.co/lMjT2iXblE #artificialintelligence, #bigdata, #bus‚Ä¶\n",
      "RT @DrTedros: 90% of high-income countries have reached the 10% #COVID19 vaccination target; 70%+ have reached the 40% target. Not 1 low-in‚Ä¶\n",
      "AIIMS Delhi to conduct Phase 2/3 clinical trials of Bharat Biotech's nasal vaccine soon.\n",
      "\n",
      "#AIIMS #Delhi #conduct‚Ä¶ https://t.co/qBo5F8jUUW\n",
      "RT @NoopurRajeMD: An amazing feat to kick off IMW 2018 @Myeloma_Society in Vienna.. 2 years later.. 500+ in person with all #covid protocol‚Ä¶\n",
      "RT @ellymelly: The Indian Bar Association charges #WHO Scientist Soumya Swaminathan for MassMurder. They accuse her of causing the deaths o‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "# Create Auth object\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Set up the listener. The 'wait_on_rate_limit=True' is needed to help with Twitter API rate limiting.\n",
    "listener = StreamListener(api=tweepy.API(wait_on_rate_limit=True, wait_on_rate_limit_notify=True, timeout=60, retry_delay=5, retry_count=10, retry_errors=set([401, 404, 500, 503])))\n",
    "stream = tweepy.Stream(auth=auth, listener=listener)\n",
    "print(\"Tracking: \" + str(WORDS))\n",
    "stream.filter(track=WORDS, languages = ['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e49e70f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
