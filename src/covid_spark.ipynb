{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0a1811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (3.6.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk) (4.62.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.9/site-packages (from nltk) (2021.8.27)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39fe762c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/08/27 06:18:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "       .builder\\\n",
    "       .appName(\"test\")\\\n",
    "       .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea33d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"hdfs://namenode:8020/tmp/data/covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be365680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|{\"userID\": 320881...|\n",
      "|{\"userID\": 926309...|\n",
      "|{\"userID\": 447289...|\n",
      "|{\"userID\": 472445...|\n",
      "|{\"userID\": 567289...|\n",
      "|{\"userID\": 102953...|\n",
      "|{\"userID\": 787182...|\n",
      "|{\"userID\": 223501...|\n",
      "|{\"userID\": 149409...|\n",
      "|{\"userID\": 724245...|\n",
      "|{\"userID\": 838192...|\n",
      "|{\"userID\": 985121...|\n",
      "|{\"userID\": 852189...|\n",
      "|{\"userID\": 119300...|\n",
      "|{\"userID\": 134640...|\n",
      "|{\"userID\": 154605...|\n",
      "|{\"userID\": 824736...|\n",
      "|{\"userID\": 530009...|\n",
      "|{\"userID\": 140798...|\n",
      "|{\"userID\": 105685...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ee08f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "schema= df.select(F.schema_of_json(\"\"\"{\n",
    "   \"userID\": 724245818299969500,\n",
    "   \"tweetText\": \"Text\",\n",
    "   \"hashTags\": [\n",
    "      \"propaganda\",\n",
    "      \"China\",\n",
    "      \"ChinaLiedPeopleDied\",\n",
    "      \"COVID\",\n",
    "      \"ChinaVirus\"\n",
    "   ],\n",
    "   \"location_full_name\": \"Merica\",\n",
    "   \"favoriteCount\": 0,\n",
    "   \"reTweetCount\": 0,\n",
    "   \"created_at\": \"Fri Aug 27 03:21:20 +0000 2021\"\n",
    "}\"\"\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33a403f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STRUCT<`created_at`: STRING, `favoriteCount`: BIGINT, `hashTags`: ARRAY<STRING>, `location_full_name`: STRING, `reTweetCount`: BIGINT, `tweetText`: STRING, `userID`: BIGINT>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c4f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"value\", F.from_json(\"value\",schema))\\\n",
    ".select(\"value.userID\", \"value.tweetText\", \"value.hashTags\", \"value.location_full_name\",\n",
    "        \"value.favoriteCount\", \"value.reTweetCount\", \"value.created_at\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79da9534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+--------------------+-------------+------------+--------------------+\n",
      "|             userID|           tweetText|            hashTags|  location_full_name|favoriteCount|reTweetCount|          created_at|\n",
      "+-------------------+--------------------+--------------------+--------------------+-------------+------------+--------------------+\n",
      "|         3208811578|Babita Deokaran h...|[BabitaDeokaran, ...|Umhlanga, South A...|            0|           0|Fri Aug 27 06:00:...|\n",
      "| 926309384615088128|The COVID-19 pand...|           [COVID19]|            Zimbabwe|            0|           0|Fri Aug 27 06:00:...|\n",
      "|           44728980|DOH says several ...|           [COVID19]|         Philippines|            0|           0|Fri Aug 27 06:00:...|\n",
      "|         4724452756|HMRC issues new S...|[SEISS5, coronavi...|Scotland, United ...|            0|           0|Fri Aug 27 06:00:...|\n",
      "|          567289542|A crisis of incre...|[Afghanistan, COV...|        Saudi Arabia|            0|           0|Fri Aug 27 06:00:...|\n",
      "|1029538560423034885|ICYMI: @CrabbBren...|           [COVID19]| Melbourne, Victoria|            0|           0|Fri Aug 27 06:00:...|\n",
      "|          787182156|As we continue th...|           [COVID19]|              Malawi|            0|           0|Fri Aug 27 06:00:...|\n",
      "|          223501074|RT @NidhiTanejaa:...|             [Covid]|    New Delhi, India|            0|           0|Fri Aug 27 06:00:...|\n",
      "|           14940946|\"de-wormer\" for a...|[ivermectin, covi...|        Outer Heaven|            0|           0|Fri Aug 27 06:00:...|\n",
      "| 724245818299969537|Claiming that's i...|[propaganda, Chin...|             'Merica|            0|           0|Fri Aug 27 03:21:...|\n",
      "| 838192517791174657|RT @AntonyRobart:...|[VaccinePassports...|              Canada|            0|           0|Fri Aug 27 03:21:...|\n",
      "| 985121348690366464|RT @EuroELSO: Lat...|     [ECMO, COVID19]|        L'Hospitalet|            0|           0|Fri Aug 27 03:21:...|\n",
      "|           85218923|#Most worrisome i...|[Most, SouthKorea...|Jeju Island, Sout...|            0|           0|Fri Aug 27 03:21:...|\n",
      "|         1193007020|RT @DrAmbrishMith...|[VaccinationDrive...|               India|            0|           0|Fri Aug 27 03:21:...|\n",
      "|1346408131367153666|@KavalAuthorActs ...|  [COVID19, COVID19]|Cape Town, South ...|            0|           0|Fri Aug 27 03:21:...|\n",
      "|          154605312|RT @SantaKlauSchw...|           [COVID19]|            STL, USA|            0|           0|Fri Aug 27 03:21:...|\n",
      "| 824736766716309504|RT @SamirShahMD: ...|           [COVID19]|Land of Enchantme...|            0|           0|Fri Aug 27 03:21:...|\n",
      "|           53000919|This expectation ...|[ThirdWave, COVID19]|             Chennai|            0|           0|Fri Aug 27 05:30:...|\n",
      "|          140798905|Watch the grand M...|             [Covid]|               India|            0|           0|Fri Aug 27 05:30:...|\n",
      "|         1056850669|More than 61 cror...|[COVID19, Largest...|    New Delhi, India|            0|           0|Fri Aug 27 05:30:...|\n",
      "+-------------------+--------------------+--------------------+--------------------+-------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b5ade",
   "metadata": {},
   "source": [
    "# Country statistic of covid tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd04d63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:======================================================>(198 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|  location_full_name|count|\n",
      "+--------------------+-----+\n",
      "|       United States|  246|\n",
      "|               India|  229|\n",
      "|    Bengaluru, India|  159|\n",
      "|     Los Angeles, CA|  124|\n",
      "|    New Delhi, India|   98|\n",
      "|           Australia|   94|\n",
      "|        New York, NY|   66|\n",
      "|       Mumbai, India|   63|\n",
      "|     California, USA|   61|\n",
      "|              Canada|   60|\n",
      "|           Worldwide|   57|\n",
      "|               Earth|   49|\n",
      "|           New Delhi|   46|\n",
      "|              Mumbai|   41|\n",
      "|           Sri Lanka|   38|\n",
      "|      Washington, DC|   36|\n",
      "|                 USA|   36|\n",
      "|        South Africa|   35|\n",
      "|Sydney, New South...|   34|\n",
      "|      United Kingdom|   32|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy('location_full_name').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea204bdf",
   "metadata": {},
   "source": [
    "# Hashtags statistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "564a974e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=====================================================> (196 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                 key|count|\n",
      "+--------------------+-----+\n",
      "|             COVID19| 4031|\n",
      "|               COVID|  711|\n",
      "|             covid19|  473|\n",
      "|             Covid19|  468|\n",
      "|         coronavirus|  335|\n",
      "|               Covid|  291|\n",
      "|               covid|  185|\n",
      "|   IndiaFightsCorona|  181|\n",
      "|             Vaccine|  162|\n",
      "|               CoWIN|  142|\n",
      "|WhatsHappeningInM...|  137|\n",
      "|      cowinblore1844|  136|\n",
      "|               India|  134|\n",
      "|           Aug27Coup|  134|\n",
      "|                BBMP|  115|\n",
      "|             vaccine|  112|\n",
      "|              Kerala|  109|\n",
      "|     MyanmarCovidSOS|  108|\n",
      "|        DeltaVariant|  104|\n",
      "|          COVISHIELD|   97|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(F.explode(df.hashTags).alias('tag'))\\\n",
    "    .groupBy(F.col('tag').alias('key'))\\\n",
    "    .count()\\\n",
    "    .orderBy('count', ascending=False)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117ed87b",
   "metadata": {},
   "source": [
    "# Clean text and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7e46d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9def9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and remove hashtag\n",
    "df_clean = df.select('tweetText', (F.lower(F.regexp_replace('tweetText', \"@[A-Za-z0-9_]+\", \"\")).alias('text')))\n",
    "\n",
    "# Tokenize text\n",
    "tokenizer = Tokenizer(inputCol='tweetText', outputCol='words_token')\n",
    "df_words_token = tokenizer.transform(df_clean).select('words_token')\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol='words_token', outputCol='words_clean')\n",
    "df_words_no_stopw = remover.transform(df_words_token).select('words_clean')\n",
    "\n",
    "# Stem text\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "stemmer_udf = F.udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "df_stemmed = df_words_no_stopw.withColumn(\"words_stemmed\", stemmer_udf(\"words_clean\")).select('words_stemmed')\n",
    "\n",
    "# Filter length word > 3\n",
    "filter_length_udf = F.udf(lambda row: [x for x in row if len(x) >= 3], ArrayType(StringType()))\n",
    "df_final_words = df_stemmed.withColumn('words', filter_length_udf(F.col('words_stemmed')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47451f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|           tweetText|                text|\n",
      "+--------------------+--------------------+\n",
      "|Babita Deokaran h...|babita deokaran h...|\n",
      "|The COVID-19 pand...|the covid-19 pand...|\n",
      "|DOH says several ...|doh says several ...|\n",
      "|HMRC issues new S...|hmrc issues new s...|\n",
      "|A crisis of incre...|a crisis of incre...|\n",
      "|ICYMI: @CrabbBren...|icymi:  from  app...|\n",
      "|As we continue th...|as we continue th...|\n",
      "|RT @NidhiTanejaa:...|rt : 26 students ...|\n",
      "|\"de-wormer\" for a...|\"de-wormer\" for a...|\n",
      "|Claiming that's i...|claiming that's i...|\n",
      "|RT @AntonyRobart:...|rt : the debate o...|\n",
      "|RT @EuroELSO: Lat...|rt : latest updat...|\n",
      "|#Most worrisome i...|#most worrisome i...|\n",
      "|RT @DrAmbrishMith...|rt : start the da...|\n",
      "|@KavalAuthorActs ...| take ivermectin ...|\n",
      "|RT @SantaKlauSchw...|rt : a lot of goo...|\n",
      "|RT @SamirShahMD: ...|rt : ðŸ’¸ðŸ˜Ÿfinancia...|\n",
      "|This expectation ...|this expectation ...|\n",
      "|Watch the grand M...|watch the grand m...|\n",
      "|More than 61 cror...|more than 61 cror...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f51fde2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|       words_stemmed|               words|\n",
      "+--------------------+--------------------+\n",
      "|[babita, deokaran...|[babita, deokaran...|\n",
      "|[covid-19, pandem...|[covid-19, pandem...|\n",
      "|[doh, say, sever,...|[doh, say, sever,...|\n",
      "|[hmrc, issu, new,...|[hmrc, issu, new,...|\n",
      "|[crisi, incred, p...|[crisi, incred, p...|\n",
      "|[icymi:, @crabbbr...|[icymi:, @crabbbr...|\n",
      "|[continu, fight, ...|[continu, fight, ...|\n",
      "|[rt, @nidhitaneja...|[@nidhitanejaa:, ...|\n",
      "|[\"de-wormer\", who...|[\"de-wormer\", who...|\n",
      "|[claim, western, ...|[claim, western, ...|\n",
      "|[rt, @antonyrobar...|[@antonyrobart:, ...|\n",
      "|[rt, @euroelso:, ...|[@euroelso:, late...|\n",
      "|[#most, worrisom,...|[#most, worrisom,...|\n",
      "|[rt, @drambrishmi...|[@drambrishmithal...|\n",
      "|[@kavalauthoract,...|[@kavalauthoract,...|\n",
      "|[rt, @santaklausc...|[@santaklauschwab...|\n",
      "|[rt, @samirshahmd...|[@samirshahmd:, ?...|\n",
      "|[expect, tepid, #...|[expect, tepid, #...|\n",
      "|[watch, grand, ms...|[watch, grand, ms...|\n",
      "|[61, crore, 22, l...|[crore, lakh, vac...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final_words.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f2382",
   "metadata": {},
   "source": [
    "# Statistic top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ea1871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:====================================================> (196 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|         key|count|\n",
      "+------------+-----+\n",
      "|    #covid19| 4442|\n",
      "|      vaccin| 1297|\n",
      "|       death| 1276|\n",
      "|      #covid| 1004|\n",
      "|        case|  869|\n",
      "|         new|  859|\n",
      "|       blame|  726|\n",
      "|       covid|  567|\n",
      "|       &amp;|  558|\n",
      "|         get|  510|\n",
      "|     #vaccin|  503|\n",
      "|       state|  496|\n",
      "|        dose|  448|\n",
      "|       peopl|  430|\n",
      "|       india|  406|\n",
      "|#coronavirus|  397|\n",
      "|     control|  393|\n",
      "|      report|  392|\n",
      "|        last|  392|\n",
      "|       biden|  391|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final_words.select(F.explode(df_final_words.words).alias('words'))\\\n",
    "    .groupBy(F.col('words').alias('key'))\\\n",
    "    .count()\\\n",
    "    .orderBy('count', ascending=False)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dad7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
