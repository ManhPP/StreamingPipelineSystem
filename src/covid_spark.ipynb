{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0a1811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.5 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2021.8.28-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759 kB 13.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk) (4.62.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk) (8.0.1)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.6.2 regex-2021.8.28\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39fe762c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/09/09 07:21:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "       .builder\\\n",
    "       .appName(\"test\")\\\n",
    "       .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea33d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"hdfs://namenode:8020/tmp/data/covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be365680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|{\"userID\": 262576...|\n",
      "|{\"userID\": 136715...|\n",
      "|{\"userID\": 291569...|\n",
      "|{\"userID\": 801579...|\n",
      "|{\"userID\": 621779...|\n",
      "|{\"userID\": 611532...|\n",
      "|{\"userID\": 125575...|\n",
      "|{\"userID\": 263616...|\n",
      "|{\"userID\": 134378...|\n",
      "|{\"userID\": 228417...|\n",
      "|{\"userID\": 295693...|\n",
      "|{\"userID\": 101110...|\n",
      "|{\"userID\": 136117...|\n",
      "|{\"userID\": 868380...|\n",
      "|{\"userID\": 240252...|\n",
      "|{\"userID\": 952247...|\n",
      "|{\"userID\": 487300...|\n",
      "|{\"userID\": 847922...|\n",
      "|{\"userID\": 121663...|\n",
      "|{\"userID\": 124078...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ee08f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "schema= df.select(F.schema_of_json(\"\"\"{\n",
    "   \"userID\": 724245818299969500,\n",
    "   \"tweetText\": \"Text\",\n",
    "   \"hashTags\": [\n",
    "      \"propaganda\",\n",
    "      \"China\",\n",
    "      \"ChinaLiedPeopleDied\",\n",
    "      \"COVID\",\n",
    "      \"ChinaVirus\"\n",
    "   ],\n",
    "   \"location_full_name\": \"Merica\",\n",
    "   \"favoriteCount\": 0,\n",
    "   \"reTweetCount\": 0,\n",
    "   \"created_at\": \"Fri Aug 27 03:21:20 +0000 2021\"\n",
    "}\"\"\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a403f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STRUCT<`created_at`: STRING, `favoriteCount`: BIGINT, `hashTags`: ARRAY<STRING>, `location_full_name`: STRING, `reTweetCount`: BIGINT, `tweetText`: STRING, `userID`: BIGINT>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c4f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"value\", F.from_json(\"value\",schema))\\\n",
    ".select(\"value.userID\", \"value.tweetText\", \"value.hashTags\", \"value.location_full_name\",\n",
    "        \"value.favoriteCount\", \"value.reTweetCount\", \"value.created_at\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79da9534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+--------------------+-------------+------------+--------------------+\n",
      "|             userID|           tweetText|            hashTags|  location_full_name|favoriteCount|reTweetCount|          created_at|\n",
      "+-------------------+--------------------+--------------------+--------------------+-------------+------------+--------------------+\n",
      "|1011102199756148737|RT @XRPisOurFutur...|           [COVID19]|              Canada|            0|           0|Thu Sep 09 04:05:...|\n",
      "|1361179981628526602|RT @FreedomIsrael...|           [COVID19]|             Romania|            0|           0|Thu Sep 09 04:05:...|\n",
      "| 868380317039591425|Wednesday 8/9/21 ...|[CoWIN_Dashboard,...|   Deccans of India |            0|           0|Thu Sep 09 04:05:...|\n",
      "|           24025273|#Hospitals are no...|[Hospitals, COVID...|St. Pete, FL, #Ra...|            0|           0|Thu Sep 09 04:05:...|\n",
      "| 952247125185720320|RT @LindaOsborne6...|[Hospitals, COVID19]|               à´•àµ‡à´°à´³à´‚|            0|           0|Thu Sep 09 04:05:...|\n",
      "|           48730051|RT @DataDrivenMD:...|           [COVID19]|           san diego|            0|           0|Thu Sep 09 04:06:...|\n",
      "|           84792215|RT @SatyendarJain...|           [Covid19]|               Delhi|            0|           0|Thu Sep 09 04:06:...|\n",
      "|1216636114523443200|RT @rameshlaus: N...|[Covid, India, Co...|Madurai South, India|            0|           0|Thu Sep 09 04:06:...|\n",
      "|          124078631|RT @kr3at: ðŸš¨REPO...|       [coronavirus]|  San Francisco Area|            0|           0|Thu Sep 09 04:06:...|\n",
      "|           25300825|RT @GreatGameIndi...|           [COVID19]|                 USA|            0|           0|Thu Sep 09 04:06:...|\n",
      "|1200833473793134593|RT @DrLiMengYAN1:...|           [COVID19]|                æ±äº¬|            0|           0|Thu Sep 09 04:05:...|\n",
      "|1410891505909125123|RT @KJBar: PM Mor...|[covid19, COVID19...|           Australia|            0|           0|Thu Sep 09 04:05:...|\n",
      "|           10025982|Ivermectin is fly...|           [COVID19]|    Phoenix, Arizona|            0|           0|Thu Sep 09 04:05:...|\n",
      "|          333888813|#India Registers ...|[India, Coronavirus]|           New Delhi|            0|           0|Thu Sep 09 04:06:...|\n",
      "|1289307389318103041|RT @tedlieu: Is t...|           [COVID19]|Women's & Gay's E...|            0|           0|Thu Sep 09 04:06:...|\n",
      "|1319300744080666624|@michaelmalice Wh...|[JimmyKimmel, COVID]|              Ottawa|            0|           0|Thu Sep 09 04:06:...|\n",
      "|         2579554963|\"We started with ...|[COVID19, COVID19...|Background by @Si...|            0|           0|Thu Sep 09 04:06:...|\n",
      "|          212496320|RT @timesofindia:...|           [COVID19]|           Gorakhpur|            0|           0|Thu Sep 09 04:06:...|\n",
      "|1338824524423331840|RT @RetweetsMumba...|[mumbai, delhi, p...|              Mumbai|            0|           0|Thu Sep 09 04:06:...|\n",
      "| 702151498013265924|RT @ANI: India re...|           [COVID19]|               India|            0|           0|Thu Sep 09 04:06:...|\n",
      "+-------------------+--------------------+--------------------+--------------------+-------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b5ade",
   "metadata": {},
   "source": [
    "# Country statistic of covid tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd04d63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:==========================================>            (154 + 5) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|  location_full_name|count|\n",
      "+--------------------+-----+\n",
      "| Melbourne, Victoria|    3|\n",
      "|           Australia|    2|\n",
      "|               India|    2|\n",
      "|        Delhi, India|    2|\n",
      "|       Paris, France|    2|\n",
      "|              Africa|    2|\n",
      "|Johannesburg, Sou...|    2|\n",
      "|        ringwood, uk|    1|\n",
      "|Women's & Gay's E...|    1|\n",
      "|             Wantage|    1|\n",
      "|              Europe|    1|\n",
      "|Far East. HN in A...|    1|\n",
      "|              Ottawa|    1|\n",
      "|  Madurai, tamilnadu|    1|\n",
      "|           Sri Lanka|    1|\n",
      "|              Berlin|    1|\n",
      "|Florence, Oregon ...|    1|\n",
      "|      Hanoi, Vietnam|    1|\n",
      "| ðŸ‡¨ðŸ‡¦â’·.â’¸. â’¸â’¶â“ƒâ’¶â’¹â’¶ðŸ‡¨ðŸ‡¦|    1|\n",
      "|            Hartwell|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:=================================================>     (180 + 4) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy('location_full_name').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea204bdf",
   "metadata": {},
   "source": [
    "# Hashtags statistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "564a974e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 6:=========================>                              (91 + 4) / 200]\r",
      "\r",
      "[Stage 6:====================================>                  (133 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                 key|count|\n",
      "+--------------------+-----+\n",
      "|             COVID19|   31|\n",
      "|         coronavirus|    8|\n",
      "|             Covid19|    5|\n",
      "|africansarenotlab...|    4|\n",
      "|             covid19|    4|\n",
      "|               covid|    4|\n",
      "|               India|    4|\n",
      "|         Coronavirus|    4|\n",
      "|artificialintelli...|    3|\n",
      "|               COVID|    3|\n",
      "|             vaccine|    3|\n",
      "|          COVID19Aus|    3|\n",
      "|             bigdata|    2|\n",
      "|           Hospitals|    2|\n",
      "|               Covid|    2|\n",
      "|          CovidIndia|    2|\n",
      "|              auspol|    2|\n",
      "|             standby|    2|\n",
      "|NoToCoronaVirusVa...|    2|\n",
      "|               Thane|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 6:===============================================>       (171 + 5) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(F.explode(df.hashTags).alias('tag'))\\\n",
    "    .groupBy(F.col('tag').alias('key'))\\\n",
    "    .count()\\\n",
    "    .orderBy('count', ascending=False)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117ed87b",
   "metadata": {},
   "source": [
    "# Clean text and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7e46d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9def9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and remove hashtag\n",
    "df_clean = df.select('tweetText', (F.lower(F.regexp_replace('tweetText', \"@[A-Za-z0-9_]+\", \"\")).alias('text')))\n",
    "\n",
    "# Tokenize text\n",
    "tokenizer = Tokenizer(inputCol='tweetText', outputCol='words_token')\n",
    "df_words_token = tokenizer.transform(df_clean).select('words_token')\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol='words_token', outputCol='words_clean')\n",
    "df_words_no_stopw = remover.transform(df_words_token).select('words_clean')\n",
    "\n",
    "# Stem text\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "stemmer_udf = F.udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "df_stemmed = df_words_no_stopw.withColumn(\"words_stemmed\", stemmer_udf(\"words_clean\")).select('words_stemmed')\n",
    "\n",
    "# Filter length word > 3\n",
    "filter_length_udf = F.udf(lambda row: [x for x in row if len(x) >= 3], ArrayType(StringType()))\n",
    "df_final_words = df_stemmed.withColumn('words', filter_length_udf(F.col('words_stemmed')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47451f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|           tweetText|                text|\n",
      "+--------------------+--------------------+\n",
      "|RT @DrEricDing: W...|rt : wowâ€”â€œevery k...|\n",
      "|We've crossed the...|we've crossed the...|\n",
      "|â­•ï¸ #Georgia repor...|â­•ï¸ #georgia repor...|\n",
      "|https://t.co/wQoL...|https://t.co/wqol...|\n",
      "|RT @NewIndianXpre...|rt : a new sublin...|\n",
      "|We urge all #work...|we urge all #work...|\n",
      "|Islamabad: Daily ...|islamabad: daily ...|\n",
      "|RT @CrabbBrendan:...|rt : brilliant pi...|\n",
      "|RT @MissStixy: #J...|rt : #janenehosko...|\n",
      "|Iâ€™ve reached that...|iâ€™ve reached that...|\n",
      "|#Coronavirus: #Th...|#coronavirus: #th...|\n",
      "|RT @XRPisOurFutur...|rt : \"the #covid1...|\n",
      "|RT @FreedomIsrael...|rt : this is how ...|\n",
      "|Wednesday 8/9/21 ...|wednesday 8/9/21 ...|\n",
      "|#Hospitals are no...|#hospitals are no...|\n",
      "|RT @LindaOsborne6...|rt : #hospitals a...|\n",
      "|RT @DataDrivenMD:...|rt : more than a ...|\n",
      "|RT @SatyendarJain...|rt : delhi govt h...|\n",
      "|RT @rameshlaus: N...|rt : new #covid c...|\n",
      "|RT @kr3at: ðŸš¨REPO...|rt : ðŸš¨report: lo...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f51fde2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|       words_stemmed|               words|\n",
      "+--------------------+--------------------+\n",
      "|[rt, @drericding:...|[@drericding:, wo...|\n",
      "|[cross, 14, milli...|[cross, million, ...|\n",
      "|[â­•ï¸, #georgia, re...|[#georgia, report...|\n",
      "|[https://t.co/wqo...|[https://t.co/wqo...|\n",
      "|[rt, @newindianxp...|[@newindianxpress...|\n",
      "|[urg, #worker, fa...|[urg, #worker, fa...|\n",
      "|[islamabad:, dail...|[islamabad:, dail...|\n",
      "|[rt, @crabbbrenda...|[@crabbbrendan:, ...|\n",
      "|[rt, @missstixy:,...|[@missstixy:, #ja...|\n",
      "|[i'v, reach, poin...|[i'v, reach, poin...|\n",
      "|[#coronavirus:, #...|[#coronavirus:, #...|\n",
      "|[rt, @xrpisourfut...|[@xrpisourfuture:...|\n",
      "|[rt, @freedomisra...|[@freedomisrael_:...|\n",
      "|[wednesday, 8/9/2...|[wednesday, 8/9/2...|\n",
      "|[#hospit, forc, r...|[#hospit, forc, r...|\n",
      "|[rt, @lindaosborn...|[@lindaosborne60:...|\n",
      "|[rt, @datadrivenm...|[@datadrivenmd:, ...|\n",
      "|[rt, @satyendarja...|[@satyendarjain:,...|\n",
      "|[rt, @rameshlaus:...|[@rameshlaus:, ne...|\n",
      "|[rt, @kr3at:, ðŸš¨r...|[@kr3at:, ðŸš¨repor...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final_words.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f2382",
   "metadata": {},
   "source": [
    "# Statistic top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ea1871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:============================================>         (165 + 6) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                 key|count|\n",
      "+--------------------+-----+\n",
      "|            #covid19|   33|\n",
      "|               &amp;|   13|\n",
      "|                 new|   10|\n",
      "|              vaccin|   10|\n",
      "|        #coronavirus|    9|\n",
      "|              43,263|    8|\n",
      "|                last|    8|\n",
      "|              #covid|    7|\n",
      "|              report|    6|\n",
      "|               death|    6|\n",
      "|               reach|    5|\n",
      "|                case|    5|\n",
      "|             #vaccin|    5|\n",
      "|              cases,|    5|\n",
      "|#africansarenotla...|    4|\n",
      "|              #india|    4|\n",
      "|               total|    4|\n",
      "|             african|    4|\n",
      "|                live|    4|\n",
      "|              infect|    4|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final_words.select(F.explode(df_final_words.words).alias('words'))\\\n",
    "    .groupBy(F.col('words').alias('key'))\\\n",
    "    .count()\\\n",
    "    .orderBy('count', ascending=False)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dad7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
